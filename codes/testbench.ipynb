{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b4T4PTKzqV7r"
      },
      "source": [
        "#  **Testbench for experimenting on 2D-CNN pipeline for Classification - PyTorch**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anuPzNOrt6MG"
      },
      "source": [
        "**Please MAKE sure that you are using GPU . Go to Runtime>> Change Runtime type  and select GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaTo9mocK2mE"
      },
      "source": [
        "#  **Connect to Google Drive**\n",
        " Allow Google Colab to connect to your GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBqs_JQVK2mI",
        "outputId": "4e651db3-4ba7-45e6-ed0a-66088dcb4ace"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Sakib Mahmud\\Documents\\VS Code\\2D_Classification_Regression_PyTorch\\Codes\\testbench.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Codes/testbench.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Codes/testbench.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/gdrive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s0cNjAMnKX8"
      },
      "source": [
        "Change the current directory to Virtual Machine (VM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LW7OK4d70Zf",
        "outputId": "2c7f3fcf-f771-43dd-b6fa-bad66a703518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDfFZdRrsvvt"
      },
      "source": [
        "List all files in the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFXsuL-Jqzzx",
        "outputId": "9e97466d-3748-495e-c501-1a99ce22e721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m_ORJ3F8RO6"
      },
      "source": [
        "# **Check GPU Status**\n",
        "Check the available GPU from the Google Server, GPU model and other related information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xskExVE68poJ",
        "outputId": "bf9e813e-2ea2-479d-d05b-e5c3a2640180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is CUDA enabled GPU Available? False\n",
            "Is GPU Initialized yet? False\n",
            "GPU Number: 0\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Sakib Mahmud\\Documents\\VS Code\\2D_Classification_Regression_PyTorch\\Pipeline\\codes\\testbench.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIs GPU Initialized yet?\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_initialized())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGPU Number:\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent GPU Index:\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mcurrent_device())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGPU Type:\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_name(device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGPU Capability:\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_capability(device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n",
            "File \u001b[1;32mc:\\Users\\Sakib Mahmud\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:482\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurrent_device\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    481\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     _lazy_init()\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_getDevice()\n",
            "File \u001b[1;32mc:\\Users\\Sakib Mahmud\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:211\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
        "print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())\n",
        "print(\"GPU Number:\", torch.cuda.device_count())\n",
        "print(\"Current GPU Index:\", torch.cuda.current_device())\n",
        "print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
        "print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDYIJo97LAIp"
      },
      "source": [
        "# **Import and Prepare Code and Dataset files** \n",
        "1- Copy dataset file and codes to your Google Colab instance (Change file names if necessary ), dont have to copy the data files to the content here, as it will be copied in the next code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIxFXP_5wSco"
      },
      "source": [
        "1- Copy the Data to the Virtual Machine\n",
        "\n",
        "2- Unzip the dataset file in the instance,\n",
        "   Please rename the downloaded file as Data.zip if it has a different name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gQ_1YEJp1hL",
        "outputId": "a8f4901f-e8b8-49a5-ec65-f1fd6a279b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwl71HW2p1ky"
      },
      "source": [
        "Import Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGfjaDzqB0Y",
        "outputId": "ec46e072-f844-455a-db8e-4d12157c3388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x4s7escuDphytkQhIwWRHcmnBNwEUkXl\n",
            "To: /content/codes.zip\n",
            "100% 583M/583M [00:05<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/'\n",
        "!gdown --id 1x4s7escuDphytkQhIwWRHcmnBNwEUkXl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-n6KbJ2LWls",
        "outputId": "0a04d7c5-b123-437c-a705-8b037c6cdee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " inflated: chexnet.pth.tar\n",
            " inflated: chexnet.py\n",
            " inflated: config.py\n",
            " inflated: config_inference.py\n",
            " inflated: config_OutputProbabilities.py\n",
            " inflated: darknet53.pth.tar\n",
            " inflated: darknet53.py\n",
            " inflated: inceptionresnetv2.pth\n",
            " inflated: Inference.py\n",
            " inflated: InferenceTime.py\n",
            " inflated: models.py\n",
            " inflated: Output_Probability.py\n",
            " inflated: README.txt\n",
            " inflated: selfonn.py\n",
            " inflated: testbench.py\n",
            " inflated: train.py\n",
            " inflated: utils.py\n",
            " inflated: xception.py\n"
          ]
        }
      ],
      "source": [
        "!jar xvf codes.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jGxFz9MqAUT"
      },
      "source": [
        "Run this code block if the ZIP extracts into a sub-folder instead of the root dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmVroGbxuO9c"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "    \n",
        "source_dir = '/content/codes'\n",
        "target_dir = '/content/'\n",
        "    \n",
        "file_names = os.listdir(source_dir)\n",
        "    \n",
        "for file_name in file_names:\n",
        "    shutil.move(os.path.join(source_dir, file_name), target_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwIyEfd-p7t7"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7bd2i7VxCdS"
      },
      "outputs": [],
      "source": [
        "%cd '/content/'\n",
        "!gdown --id 1UJLb-oRfZ4yUbP-6RkFaq1mGOXX4Dw6N\n",
        "!jar xvf Data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qW6Kr8h8_Yt"
      },
      "source": [
        "# **Install and Import Required Libraries**\n",
        "Use 'pip' to install libraries. Put '!' i.e. Exclamation Mark before each command, exclusive to Jupyter Notebooks. Some are already installed by Google Colab and others are required. If the IMPORT statements are present in the python code being run, no need to follow this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DWQ0w4Qukcb"
      },
      "source": [
        "Install or Update Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SLEyGg639B5w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (0.19.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (1.7.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (9.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (1.21.5)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from scikit-image) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from packaging>=20.0->scikit-image) (3.0.4)\n",
            "Requirement already satisfied: ipython in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (8.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.1.2)\n",
            "Requirement already satisfied: backcall in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.18.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.4.4)\n",
            "Requirement already satisfied: traitlets>=5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (2.11.2)\n",
            "Requirement already satisfied: stack-data in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (61.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (3.0.20)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: executing in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from stack-data->ipython) (0.8.3)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
            "Requirement already satisfied: asttokens in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from stack-data->ipython) (2.0.5)\n",
            "Requirement already satisfied: six in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython) (1.16.0)\n",
            "Requirement already satisfied: Pillow in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (9.0.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (9.0.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.15 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from seaborn) (1.21.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from seaborn) (3.5.1)\n",
            "Requirement already satisfied: scipy>=1.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.23 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from seaborn) (1.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
            "Requirement already satisfied: gdown in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (4.5.1)\n",
            "Requirement already satisfied: six in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
            "Collecting efficientnet-pytorch\n",
            "  Using cached efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from efficientnet-pytorch) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py): started\n",
            "  Building wheel for efficientnet-pytorch (setup.py): finished with status 'done'\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=bfe8754a6ce7ebcc21342a81321dc4423766db4f0902642e25fbd719aebe9f11\n",
            "  Stored in directory: c:\\users\\sakib mahmud\\appdata\\local\\pip\\cache\\wheels\\29\\16\\24\\752e89d88d333af39a288421e64d613b5f652918e39ef1f8e3\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "Requirement already satisfied: torch>=1.7 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from timm) (1.12.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from timm) (0.13.1)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from timm) (6.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (2022.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->timm) (0.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torchvision->timm) (9.0.1)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 timm-0.6.13\n",
            "Requirement already satisfied: tqdm in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (4.64.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
            "Collecting torchviz\n",
            "  Using cached torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torchviz) (1.12.1)\n",
            "Collecting graphviz\n",
            "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (from torch->torchviz) (4.1.1)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py): started\n",
            "  Building wheel for torchviz (setup.py): finished with status 'done'\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=4f77172c81d9838f5b6a3d87887a2b58c79d8cedf2c0f65a265ea77df05d8a8b\n",
            "  Stored in directory: c:\\users\\sakib mahmud\\appdata\\local\\pip\\cache\\wheels\\29\\65\\6e\\db2515eb1dc760fecd36b40d54df65c1e18534013f1c037e2e\n",
            "Successfully built torchviz\n",
            "Installing collected packages: graphviz, torchviz\n",
            "Successfully installed graphviz-0.20.1 torchviz-0.0.2\n",
            "Requirement already satisfied: graphviz in c:\\users\\sakib mahmud\\anaconda3\\lib\\site-packages (0.20.1)\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch==1.11.0 torchvision==0.12.0 torchaudio\n",
        "# !pip install torchvision\n",
        "# !pip install torchsummary\n",
        "# !pip install numpy\n",
        "# !pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-image\n",
        "!pip install ipython\n",
        "!pip install Pillow\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install gdown\n",
        "!pip install efficientnet-pytorch\n",
        "!pip install timm\n",
        "!pip install tqdm\n",
        "!pip install torchviz\n",
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dLXYMfPun1W"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aMaUgR199h58"
      },
      "outputs": [],
      "source": [
        "# Printing out all outputs\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim, cuda, tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import densenet201, DenseNet201_Weights\n",
        "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
        "# warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "# Data science tools\n",
        "import os\n",
        "import timm\n",
        "import numpy as np\n",
        "from os import path\n",
        "from importlib import import_module\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.size'] = 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYnz-wSso9Pi"
      },
      "source": [
        "# **MAIN**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr-_BxGEqxQG"
      },
      "source": [
        "Print Pipeline options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hw012sZtb60",
        "outputId": "543e5f51-d1d7-4637-a766-011b840a34b1"
      },
      "outputs": [],
      "source": [
        "f = open(\"README.txt\", \"r\")\n",
        "print(f.read())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_file = torch.load('C:/Users/Sakib Mahmud/Documents/VS Code/2D_Feature_Extractor_PyTorch/Trained_Models/DenseNet201_Tumor_Classification_Fold_1.pt')\n",
        "print(model_file.keys())\n",
        "model = models.densenet201(pretrained=True)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'SelfONN'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Sakib Mahmud\\Documents\\VS Code\\2D_Classification_Regression_PyTorch\\Pipeline\\codes\\testbench.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sakib%20Mahmud/Documents/VS%20Code/2D_Classification_Regression_PyTorch/Pipeline/codes/testbench.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSelfONN\u001b[39;00m \u001b[39mimport\u001b[39;00m SuperONN1d, SuperONN2d, SelfONN1d, SelfONN2d\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SelfONN'"
          ]
        }
      ],
      "source": [
        "from SelfONN import SuperONN1d, SuperONN2d, SelfONN1d, SelfONN2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN_Classifier(nn.Module):\n",
        "    def __init__(self, in_channels, class_num, final_activation):\n",
        "        super().__init__()\n",
        "        if final_activation == 'ELU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.ELU(alpha=1.0, inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'Hardshrink':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Hardshrink(lambd=0.5)\n",
        "                )\n",
        "        elif final_activation == 'Hardsigmoid':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Hardsigmoid(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'Hardtanh':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Hardtanh(min_val= 0.0, max_val=1.0, inplace=False, min_value=None, max_value=None)\n",
        "                )\n",
        "        elif final_activation == 'Hardswish':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Hardswish(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'Hardtanh':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False, min_value=None, max_value=None)\n",
        "                )\n",
        "        elif final_activation == 'LeakyReLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'LogSigmoid':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.LogSigmoid()\n",
        "                )\n",
        "        elif final_activation == 'LogSoftmax':\n",
        "            self.classifier = nn.Sequential(\n",
        "                UnSqueezeLayer(),\n",
        "                nn.Tanh(),\n",
        "                SelfONN2d(in_channels=in_channels, out_channels=class_num, kernel_size=1, q=1, mode='fast', dropout=None),\n",
        "                nn.Tanh(),\n",
        "                SqueezeLayer(),\n",
        "                nn.LogSoftmax(dim=1) \n",
        "            )\n",
        "        elif final_activation == 'PReLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.PReLU(num_parameters=1, init=0.25, device=None, dtype=None)\n",
        "                )\n",
        "        elif final_activation == 'ReLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.ReLU(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'ReLU6':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.ReLU6(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'RReLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'SELU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.SELU(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'CELU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.CELU(alpha=1.0, inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'GELU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.GELU(approximate='none')\n",
        "                )\n",
        "        elif final_activation == 'Sigmoid':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Sigmoid()\n",
        "                )\n",
        "        elif final_activation == 'SiLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.SiLU(inplace=False)\n",
        "                )\n",
        "        elif final_activation == 'Softmin':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softmin(dim=None)\n",
        "                )\n",
        "        elif final_activation == 'Softmax':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softmax(dim=None)\n",
        "                )\n",
        "        elif final_activation == 'Softmax2d':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softmax2d()\n",
        "                )\n",
        "        elif final_activation == 'Softplus':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softplus(beta=1, threshold=20)\n",
        "                )\n",
        "        elif final_activation == 'Softshrink':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softshrink(lambd=0.5)\n",
        "                )\n",
        "        elif final_activation == 'Softsign':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Softsign()\n",
        "                )\n",
        "        elif final_activation == 'Tanh':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Tanh()\n",
        "                )\n",
        "        elif final_activation == 'Tanhshrink':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.Tanhshrink()\n",
        "                )\n",
        "        elif final_activation == 'GLU':\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(in_channels, class_num),\n",
        "                nn.GLU(dim=-1)\n",
        "                )\n",
        "        torch.nn.init.xavier_uniform_(self.classifier[0].weight)\n",
        "        self.classifier[0].bias.data.fill_(0.01) \n",
        "     \n",
        "    def forward(self,x):\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SqueezeLayer(nn.Module):\n",
        "    def forward(self,x):\n",
        "        x = x.squeeze(2)\n",
        "        x = x.squeeze(2)\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnSqueezeLayer(nn.Module):\n",
        "    def forward(self,x):\n",
        "        x = x.unsqueeze(2).unsqueeze(3)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.regnet_y_400mf(weights='IMAGENET1K_V1')\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = CNN_Classifier(in_channels=num_ftrs, class_num=2, final_activation='LogSigmoid')\n",
        "x = torch.rand(8, 3, 224, 224)\n",
        "y = model(x)\n",
        "target = torch.Tensor([1,0,0,0,0,1,1,1])\n",
        "print(y.size())\n",
        "print(target.size())\n",
        "criterion = nn.NLLLoss()\n",
        "loss = criterion(y,target)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract single targeted layers from pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_layer_1 = model.features.transition1.conv\n",
        "extracted_layer_2 = model.features.transition2.conv\n",
        "extracted_layer_3 = model.features.transition3.conv\n",
        "extracted_layer_4 = model.features.denseblock4.denselayer32.conv1\n",
        "print(extracted_layer_1)\n",
        "print(extracted_layer_2)\n",
        "print(extracted_layer_3)\n",
        "print(extracted_layer_4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract a chunk of pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.inception_v3(weights='DEFAULT')\n",
        "Conv0 = nn.Sequential(*list(model.children())[0:])\n",
        "Conv1 = nn.Sequential(*list(model.children())[10:10])\n",
        "Conv2 = nn.Sequential(*list(model.children())[0:15])\n",
        "Conv3 = nn.Sequential(*list(model.children())[0:15],*list(model.children())[16:19])\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
        "Conv1 = nn.Sequential(model.features)\n",
        "print(Conv1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.densenet201(weights='DEFAULT')\n",
        "Conv1 = nn.Sequential(*list(model.features.children())[0:5])\n",
        "Conv2 = nn.Sequential(*list(model.features.children())[0:7])\n",
        "Conv3 = nn.Sequential(*list(model.features.children())[0:9])\n",
        "Conv4 = nn.Sequential(*list(model.features.children())[0:])\n",
        "print(Conv2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PHNet(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(PHNet, self).__init__()\n",
        "        model1 = models.densenet201(weights='DEFAULT')\n",
        "        model2 = models.inception_v3(weights='DEFAULT')\n",
        "        self.ExtractedDenseBlock1 = nn.Sequential(*list(model1.features.children())[0:7])\n",
        "        self.ExtractedDenseBlock2 = nn.Sequential(*list(model1.features.children())[0:9])\n",
        "        self.ExtractedDenseBlock3 = nn.Sequential(*list(model1.features.children())[0:])\n",
        "        self.ExtractedInceptionBlocks1 = nn.Sequential(*list(model2.children())[0:10])\n",
        "        self.ExtractedInceptionBlocks2 = nn.Sequential(*list(model2.children())[0:15])\n",
        "        self.ExtractedInceptionBlocks3 = nn.Sequential(*list(model2.children())[0:15],*list(model2.children())[16:19])\n",
        "        self.zeropad1 = nn.ZeroPad2d((1, 1, 1, 1))\n",
        "        self.zeropad2 = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.aux1 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(800, 50, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(50, 800, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(800, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux2 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=3),\n",
        "            nn.Conv2d(2560, 320, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(320, 2560, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2560, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.final_classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3968, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        Dout1 = self.ExtractedDenseBlock1(x)\n",
        "        Dout2 = self.ExtractedDenseBlock2(x)\n",
        "        Dout3 = self.ExtractedDenseBlock3(x)\n",
        "        Iout1 = self.upsample(self.zeropad1(torch.max_pool2d(self.ExtractedInceptionBlocks1(x),2)))\n",
        "        Iout2 = self.upsample(self.zeropad2(torch.max_pool2d(self.ExtractedInceptionBlocks2(x),2)))\n",
        "        Iout3 = self.zeropad1(self.ExtractedInceptionBlocks3(x))\n",
        "        out1 = torch.cat((Dout1, Iout1), dim=1)\n",
        "        out2 = torch.cat((Dout2, Iout2), dim=1)\n",
        "        out3 = torch.cat((Dout3, Iout3), dim=1)\n",
        "        final_out1 = self.aux1(out1)\n",
        "        final_out2 = self.aux2(out2)\n",
        "        final_out3 = self.final_classifier(out3)\n",
        "        return final_out3, final_out2, final_out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 800, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sakib Mahmud\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:139: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "N, C, H, W = 10, 3, 224, 224\n",
        "x = torch.empty(N, C, H, W)\n",
        "# y = x.to(memory_format=torch.channels_last)\n",
        "# print(x.size())\n",
        "# print(x.stride())  # Ouputs: (3072, 1024, 32, 1)\n",
        "\n",
        "y = PHNet(3)(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modfied DenseNet201 Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Modified_DenseNet201(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(Modified_DenseNet201, self).__init__()\n",
        "        model = models.densenet201(weights='IMAGENET1K_V1')\n",
        "        self.ExtractedDenseBlock1 = nn.Sequential(*list(model.features.children())[0:6])\n",
        "        self.ExtractedDenseBlock2 = nn.Sequential(*list(model.features.children())[0:8])\n",
        "        self.ExtractedDenseBlock3 = nn.Sequential(*list(model.features.children())[0:10])\n",
        "        self.ExtractedDenseBlock4 = nn.Sequential(*list(model.features.children())[0:])\n",
        "        self.downSamp1 = nn.MaxPool2d(4)\n",
        "        self.downSamp2 = nn.MaxPool2d(2)\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3200, 160, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(160*7*7, class_num),\n",
        "            nn.LogSoftmax(dim=None)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = self.ExtractedDenseBlock1(x)\n",
        "        out2 = self.ExtractedDenseBlock2(x)\n",
        "        out3 = self.ExtractedDenseBlock3(x)\n",
        "        out4 = self.ExtractedDenseBlock4(x)\n",
        "        out1 = self.downSamp1(out1)\n",
        "        out2 = self.downSamp2(out2)\n",
        "        out_cat = torch.cat((out1,out2,out3,out4), dim=1)\n",
        "        out = self.conv1(out_cat)\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modified DenseNet201 Model with multiple Auxilliary Losses and Multiheaded Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Modified_DenseNet201_AUX(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(Modified_DenseNet201_AUX, self).__init__()\n",
        "        model = models.densenet201(weights='IMAGENET1K_V1')\n",
        "        self.ExtractedDenseBlock1 = nn.Sequential(*list(model.features.children())[0:5])\n",
        "        self.ExtractedDenseBlock2 = nn.Sequential(*list(model.features.children())[0:7])\n",
        "        self.ExtractedDenseBlock3 = nn.Sequential(*list(model.features.children())[0:9])\n",
        "        self.ExtractedDenseBlock4 = nn.Sequential(*list(model.features.children())[0:])\n",
        "        self.downSamp1 = nn.MaxPool2d(8)\n",
        "        self.downSamp2 = nn.MaxPool2d(4)\n",
        "        self.downSamp3 = nn.MaxPool2d(2)\n",
        "        self.aux1 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=7, stride=3),\n",
        "            nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(64, 256, kernel_size=7, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux2 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(512, 128, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(128, 512, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux3 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=3),\n",
        "            nn.Conv2d(1792, 224, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(224, 1792, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1792, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.final_classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4480, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = self.ExtractedDenseBlock1(x)\n",
        "        out2 = self.ExtractedDenseBlock2(x)\n",
        "        out3 = self.ExtractedDenseBlock3(x)\n",
        "        out4 = self.ExtractedDenseBlock4(x)\n",
        "        out1_1 = self.downSamp1(out1)\n",
        "        out2_1 = self.downSamp2(out2)\n",
        "        out3_1 = self.downSamp3(out3)\n",
        "        out_cat = torch.cat((out1_1, out2_1, out3_1, out4), dim=1)\n",
        "        final_out1 = self.aux1(out1)\n",
        "        final_out2 = self.aux2(out2)\n",
        "        final_out3 = self.aux3(out3)\n",
        "        final_out4 = self.final_classifier(out_cat)\n",
        "        return final_out4, final_out3, final_out2, final_out1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modified InceptionV3 model a multiheaded classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Modified_InceptionV3(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(Modified_InceptionV3, self).__init__()\n",
        "        model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "        self.ExtractedInceptionBlocks1 = nn.Sequential(*list(model.children())[0:10])\n",
        "        self.ExtractedInceptionBlocks2 = nn.Sequential(*list(model.children())[0:15])\n",
        "        self.ExtractedInceptionBlocks3 = nn.Sequential(*list(model.children())[0:15],*list(model.children())[16:19])\n",
        "        self.downSamp1 = nn.MaxPool2d(4)\n",
        "        self.downSamp2 = nn.MaxPool2d(2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3104, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = self.ExtractedInceptionBlocks1(x)\n",
        "        out2 = self.ExtractedInceptionBlocks2(x)\n",
        "        out3 = self.ExtractedInceptionBlocks3(x)\n",
        "        out1 = self.downSamp1(out1)\n",
        "        out2 = self.downSamp2(out2)\n",
        "        out_cat = torch.cat((out1,out2,out3), dim=1)\n",
        "        out = self.classifier(out_cat)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modified InceptionV3 model with a Multiheaded classifier and Auxilliary Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Modified_InceptionV3_AUX(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(Modified_InceptionV3_AUX, self).__init__()\n",
        "        model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "        self.ExtractedInceptionBlocks1 = nn.Sequential(*list(model.children())[0:10])\n",
        "        self.ExtractedInceptionBlocks2 = nn.Sequential(*list(model.children())[0:15])\n",
        "        self.ExtractedInceptionBlocks3 = nn.Sequential(*list(model.children())[0:15],*list(model.children())[16:19])\n",
        "        self.downSamp1 = nn.MaxPool2d(4)\n",
        "        self.downSamp2 = nn.MaxPool2d(2)\n",
        "        self.aux1 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=7, stride=3),\n",
        "            nn.Conv2d(288, 72, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(72, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(72, 288, kernel_size=7, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(288, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(288, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux2 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(768, 128, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(128, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(128, 768, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(768, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(768, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.final_classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3104, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = self.ExtractedInceptionBlocks1(x)\n",
        "        out2 = self.ExtractedInceptionBlocks2(x)\n",
        "        out3 = self.ExtractedInceptionBlocks3(x)\n",
        "        out1_1 = self.downSamp1(out1)\n",
        "        out2_1 = self.downSamp2(out2)\n",
        "        out_cat = torch.cat((out1_1,out2_1,out3), dim=1)\n",
        "        final_out1 = self.aux1(out1)\n",
        "        final_out2 = self.aux2(out2)\n",
        "        final_out3 = self.final_classifier(out_cat)\n",
        "        return final_out3, final_out2, final_out1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DenseNet201 + InceptionV3 with Auxilliary Losses= DenseInception_AUX Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseInception_AUX(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(DenseInception_AUX, self).__init__()\n",
        "        model_densenet201 = models.densenet201(weights='IMAGENET1K_V1')\n",
        "        model_inceptionv3 = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "        self.ExtractedDenseBlock = nn.Sequential(\n",
        "          *list(model_densenet201.features.children()),\n",
        "          nn.MaxPool2d(2, stride=None, padding=0, dilation=1)\n",
        "          )\n",
        "        self.ExtractedInceptionBlock = nn.Sequential(\n",
        "          *list(model_inceptionv3.children())[0:15],*list(model_inceptionv3.children())[16:19],\n",
        "          nn.MaxPool2d(2, stride=None, padding=0, dilation=1)\n",
        "          )\n",
        "        self.final_classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3968, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux1 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(1920, 240, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(240, 1920, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1920, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "        self.aux2 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(256, 2048, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(2048, eps=1e-03, momentum=0.1, affine=True),\n",
        "            nn.ReLU6(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, class_num),\n",
        "            nn.LogSoftmax()\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out_densenet201 = self.ExtractedDenseBlock(x)\n",
        "        out_inceptionv3 = self.ExtractedInceptionBlock(x)\n",
        "        out_cat = torch.cat((out_densenet201, out_inceptionv3), dim=1)\n",
        "        final_out1 = self.final_classifier(out_cat)\n",
        "        final_out2 = self.aux1(out_densenet201)\n",
        "        final_out3 = self.aux2(out_inceptionv3)\n",
        "        return final_out1, final_out2, final_out3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 32, 32, 3])\n",
            "torch.Size([10, 32, 32, 3])\n",
            "(3072, 96, 3, 1)\n",
            "(3072, 1, 96, 32)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "N, C, H, W = 10, 32, 32, 3\n",
        "x = torch.empty(N, C, H, W)\n",
        "y = x.to(memory_format=torch.channels_last)\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(x.stride())  # Ouputs: (3072, 1024, 32, 1)\n",
        "print(y.stride())  # Ouputs: (3072, 1024, 32, 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract all layers in a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_nodes, eval_nodes = get_graph_node_names(model)\n",
        "print(train_nodes)\n",
        "print(len(train_nodes))\n",
        "# print(len(eval_nodes))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Return specific nodes of a model and create a partial architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "return_nodes = {\n",
        "    'features.transition2.relu': 'layer1',\n",
        "}\n",
        "create_feature_extractor(model, return_nodes=return_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN1QwFQ9nMx5"
      },
      "source": [
        "# **Move Files to and fro GDrive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n9FpMpYKiP6"
      },
      "source": [
        "## Copy Experiment Results from Virtual Machine or VM (Contents) to a Google Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMEk0eozKiXR"
      },
      "outputs": [],
      "source": [
        "!cp -av '/content/Results/' '/content/GDrive/MyDrive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w8RJye8CHPP"
      },
      "source": [
        "## Copy Documents from a Google Drive Folder to VM (Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlzqK7tQCHVm"
      },
      "outputs": [],
      "source": [
        "!cp -av '/content/GDrive/MyDrive/Research/Kidney_AHN_Segmentation/Results' '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb9bfwmQCDK0"
      },
      "source": [
        "## Remove non-empty Directory from the VM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF4O2frCBuh1"
      },
      "outputs": [],
      "source": [
        "shutil.rmtree('/content/Results')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzN8JkTGnI-A"
      },
      "source": [
        "# **Infinite Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAwrsQdASrLI"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "b4T4PTKzqV7r",
        "DaTo9mocK2mE",
        "2m_ORJ3F8RO6",
        "cDYIJo97LAIp",
        "1qW6Kr8h8_Yt",
        "RYnz-wSso9Pi",
        "2h73Iahis9l4",
        "XRXh2KZypNUm",
        "E7N-0H1X96gC",
        "iYYQPIgmtJC7",
        "lN1QwFQ9nMx5",
        "PzN8JkTGnI-A"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "18df5be49554eac9137ad9560d7622572b5d1ff76698513bc12df1f56f9d5feb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
